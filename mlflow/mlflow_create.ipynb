{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/melk/miniconda3/envs/WLS_CPU_python/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-01-28 00:48:30.434310: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-28 00:48:30.580932: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-28 00:48:30.580960: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-01-28 00:48:31.654512: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-28 00:48:31.654674: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-28 00:48:31.654690: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_map = {0: \"negative\", 1: \"positive\"}\n",
    "emotion_map = {0: \"anger\", 1: \"fear\", 2 : \"joy\", 3: \"sadness\"}\n",
    "download = False\n",
    "save_model_locally= False\n",
    "if download:\n",
    "    tokenizer_s = AutoTokenizer.from_pretrained(\"MilaNLProc/feel-it-italian-sentiment\", cache_dir=\"data/\")\n",
    "    model_s = AutoModelForSequenceClassification.from_pretrained(\"MilaNLProc/feel-it-italian-sentiment\", cache_dir=\"data/\")\n",
    "    model_s.eval()\n",
    "    tokenizer_emo = AutoTokenizer.from_pretrained(\"MilaNLProc/feel-it-italian-emotion\", cache_dir=\"data/\")\n",
    "    model_emo = AutoModelForSequenceClassification.from_pretrained(\"MilaNLProc/feel-it-italian-emotion\", cache_dir=\"data/\")\n",
    "    model_emo.eval()\n",
    "    if save_model_locally:\n",
    "        model.save_pretrained('./local_models/sentiment_ITA')\n",
    "        tokenizer.save_pretrained('./local_models/sentiment_ITA')\n",
    "        model_emo.save_pretrained('./local_models/emotion_ITA')\n",
    "        tokenizer_emo.save_pretrained('./local_models/emotion_ITA')\n",
    "else:\n",
    "    tokenizer_s = AutoTokenizer.from_pretrained(\"./local_models/sentiment_ITA/\")\n",
    "    model_s = AutoModelForSequenceClassification.from_pretrained(\"./local_models/sentiment_ITA/\", num_labels=2)\n",
    "    model_s.eval()\n",
    "    tokenizer_emo = AutoTokenizer.from_pretrained(\"./local_models/emotion_ITA/\")\n",
    "    model_emo = AutoModelForSequenceClassification.from_pretrained(\"./local_models/emotion_ITA/\", num_labels=4)\n",
    "    model_emo.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/melk/miniconda3/envs/WLS_CPU_python/lib/python3.8/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar funcionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import re\n",
    "\n",
    "generator = pipeline(task=\"text-classification\", model=model_s, tokenizer=tokenizer_s, return_all_scores =True)\n",
    "generator_emo = pipeline(task=\"text-classification\", model=model_emo, tokenizer=tokenizer_emo, return_all_scores =True)\n",
    "\n",
    "def sentiment_emoji(input_abs):\n",
    "\n",
    "    if(input_abs ==\"\"):\n",
    "        return \"ü§∑‚Äç‚ôÇÔ∏è\"\n",
    "        \n",
    "    res = generator(input_abs)[0]\n",
    "    res = {res[x][\"label\"]: res[x][\"score\"] for x in range(len(res))}\n",
    "    res[\"üôÇ\"] = res.pop(\"positive\")\n",
    "    res[\"üôÅ\"] = res.pop(\"negative\")\n",
    "    return res\n",
    "\n",
    "\n",
    "def emotion_emoji(input_abs):\n",
    "    if(input_abs ==\"\"):\n",
    "        return \"ü§∑‚Äç‚ôÇÔ∏è\"\n",
    "\n",
    "    res = generator_emo(input_abs)[0]\n",
    "    res = {res[x][\"label\"]: res[x][\"score\"] for x in range(len(res))}\n",
    "    res[\"üòÉ\"] = res.pop(\"joy\")\n",
    "    res[\"üò°\"] = res.pop(\"anger\")\n",
    "    res[\"üò®\"] = res.pop(\"fear\")\n",
    "    res[\"üòü\"] = res.pop(\"sadness\")\n",
    "   \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow.pyfunc\n",
    "model_path_sentiment = \"NLP_model_sentiment\"\n",
    "model_path_emotions = \"NLP_model_emotions\"\n",
    "\n",
    "# Define the model class\n",
    "class NPL_model_sentiment(mlflow.pyfunc.PythonModel):\n",
    "    def __init__(self, in_string):\n",
    "        self.input = in_string\n",
    "\n",
    "    def predict(self, context, model_input):\n",
    "        generator = pipeline(task=\"text-classification\", model=model_s, tokenizer=tokenizer_s, return_all_scores =True)\n",
    "        return generator(model_input)\n",
    "\n",
    "\n",
    "# Define the model class\n",
    "class NPL_model_emotions(mlflow.pyfunc.PythonModel):\n",
    "    def __init__(self, in_string):\n",
    "        self.input = in_string\n",
    "\n",
    "    def predict(self, context, model_input):\n",
    "        generator_emo = pipeline(task=\"text-classification\", model=model_emo, tokenizer=tokenizer_emo, return_all_scores =True)\n",
    "        return generator_emo(model_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mlflow.end_run()\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/01/28 00:48:52 WARNING mlflow.utils.requirements_utils: Found torch version (1.13.1+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==1.13.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "Registered model 'Sentiment' already exists. Creating a new version of this model...\n",
      "2023/01/28 00:48:55 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: Sentiment, version 3\n",
      "Created version '3' of model 'Sentiment'.\n",
      "2023/01/28 00:49:03 WARNING mlflow.utils.requirements_utils: Found torch version (1.13.1+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==1.13.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "Registered model 'Emotions' already exists. Creating a new version of this model...\n",
      "2023/01/28 00:49:06 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: Emotions, version 3\n",
      "Created version '3' of model 'Emotions'.\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment('text-classification-sentiment')\n",
    "with mlflow.start_run():\n",
    "    mlflow.pyfunc.log_model(artifact_path=model_path_sentiment, \n",
    "                    loader_module=None, \n",
    "                    data_path=None, \n",
    "                    code_path=None,\n",
    "                    python_model=NPL_model_sentiment(in_string = \"sono molto felice\"),\n",
    "                    registered_model_name=\"Sentiment\"\n",
    "                    )\n",
    "\n",
    "mlflow.set_experiment('text-classification-emotions')\n",
    "with mlflow.start_run():\n",
    "    mlflow.pyfunc.log_model(artifact_path=model_path_emotions, \n",
    "                    loader_module=None, \n",
    "                    data_path=None, \n",
    "                    code_path=None,\n",
    "                    python_model=NPL_model_emotions(in_string = \" Io ti estirper√≤ Saruman, come il veleno viene estirpato da una ferita‚Ä¶ Saruman: Vai via tu, io sono l'ospite!\"),\n",
    "                    registered_model_name=\"Emotions\"\n",
    "                    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WLS_CPU_python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0 (default, Nov  6 2019, 21:49:08) \n[GCC 7.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "55bea8bc0bcce7d1449ebbc846a52ee790af1253b09d4e148b05ec45c8d23b31"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
